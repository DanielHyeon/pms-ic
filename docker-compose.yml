services:
  # ============================================
  # Database Services
  # ============================================

  postgres:
    image: postgres:15-alpine
    container_name: pms-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-pms_db}
      POSTGRES_USER: ${POSTGRES_USER:-pms_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-pms_password}
      POSTGRES_MULTIPLE_DATABASES: auth,project,task,chat,risk,report
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init:/docker-entrypoint-initdb.d
    networks:
      - pms-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pms_user -d pms_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================
  # Cache & Session Store
  # ============================================

  redis:
    image: redis:7-alpine
    container_name: pms-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - pms-network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================
  # Backend Service (Modular Monolith)
  # ============================================

  backend:
    build:
      context: ./PMS_IC_BackEnd_v1.2
      dockerfile: Dockerfile
    container_name: pms-backend
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-dev}
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-pms_db}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER:-pms_user}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD:-pms_password}
      SPRING_REDIS_HOST: ${REDIS_HOST:-redis}
      SPRING_REDIS_PORT: ${REDIS_PORT:-6379}
      AI_SERVICE_URL: ${AI_SERVICE_URL:-http://llm-service:8000}
      AI_SERVICE_MOCK_URL: http://mockserver:1080
      AI_SERVICE_MODEL: ${AI_SERVICE_MODEL:-google.gemma-3-12b-pt.Q5_K_M.gguf}
      JWT_SECRET: ${JWT_SECRET:-your-secret-key-change-in-production}
    ports:
      - "8083:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      # llm-service:
      #   condition: service_healthy
    networks:
      - pms-network
    volumes:
      - backend_cache:/root/.m2
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8080/actuator/health > /dev/null 2>&1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================
  # Frontend Service
  # ============================================

  frontend:
    build:
      context: ./PMS_IC_FrontEnd_v1.2
      dockerfile: Dockerfile.dev
    container_name: pms-frontend
    environment:
      VITE_API_URL: http://localhost:8083/api
    ports:
      - "5173:5173"
    volumes:
      - ./PMS_IC_FrontEnd_v1.2:/app
      - /app/node_modules
    networks:
      - pms-network
    depends_on:
      - backend

  # ============================================
  # Local LLM Service (Flask + llama-cpp-python)
  # ============================================

  llm-service:
    profiles:
      - llm  # Enable with: docker-compose --profile llm up
    build:
      context: ./llm-service
      dockerfile: ${LLM_DOCKERFILE:-Dockerfile.gpu}
    container_name: pms-llm-service
    ports:
      - "8000:8000"
    volumes:
      - ./llm-service:/app
    networks:
      - pms-network
    # NVIDIA GPU support
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      MODEL_PATH: /app/models/google.gemma-3-12b-pt.Q5_K_M.gguf
      PORT: 8000
      MAX_TOKENS: 128
      TEMPERATURE: 0.7
      TOP_P: 0.9
      LLM_N_GPU_LAYERS: ${LLM_N_GPU_LAYERS:-35}
      LLM_N_CTX: ${LLM_N_CTX:-4096}
      LLM_N_THREADS: ${LLM_N_THREADS:-32}
      EMBEDDING_DEVICE: ${EMBEDDING_DEVICE:-cuda}
      MINERU_DEVICE: ${MINERU_DEVICE:-cuda}
      VECTOR_DB: neo4j
      NEO4J_URI: ${NEO4J_URI:-bolt://neo4j:7687}
      NEO4J_USER: ${NEO4J_USER:-neo4j}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-pmspassword123}
      USE_GRAPH_RAG: true
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ============================================
  # Vector Database (Qdrant for RAG - disabled by default)
  # ============================================

  qdrant:
    profiles:
      - qdrant
    image: qdrant/qdrant:latest
    container_name: pms-qdrant
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    networks:
      - pms-network
    healthcheck:
      test: timeout 10 bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  # ============================================
  # Graph Database (Neo4j for GraphRAG)
  # ============================================

  neo4j:
    image: neo4j:5.20-community
    container_name: pms-neo4j
    ports:
      - "7474:7474"  # Browser UI
      - "7687:7687"  # Bolt protocol
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    networks:
      - pms-network
    environment:
      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-pmspassword123}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_server_memory_heap_initial__size=512m
      - NEO4J_server_memory_heap_max__size=2G
      - NEO4J_server_memory_pagecache_size=1G
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:7474"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # ============================================
  # Graph Vector Database (Helix-DB - DEPRECATED)
  # ============================================

  helix-db:
    profiles:
      - deprecated
    build:
      context: ./helix-db
      dockerfile: Dockerfile
    container_name: pms-helix-db
    volumes:
      - helix_data:/workspace/data
      - ./helix-db/schema:/workspace/schema
      - ./helix-db/start.sh:/workspace/start.sh:ro
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - pms-network
    environment:
      - HELIX_ENV=development
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "bash", "-c", "curl -f http://host.docker.internal:6969/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ChromaDB (deprecated, keeping for migration)
  # chromadb:
  #   image: chromadb/chroma:latest
  #   container_name: pms-chromadb
  #   ports:
  #     - "8001:8000"
  #   volumes:
  #     - chromadb_data:/data
  #   environment:
  #     - IS_PERSISTENT=TRUE
  #     - ANONYMIZED_TELEMETRY=FALSE
  #   networks:
  #     - pms-network

  # ============================================
  # AI Service (Mock - Fallback용)
  # ============================================

  ai-service:
    image: mockserver/mockserver:latest
    container_name: pms-ai-service-mock
    ports:
      - "1080:1080"
    environment:
      MOCKSERVER_INITIALIZATION_JSON_PATH: /config/ai-mock.json
    volumes:
      - ./docker/mockserver/ai-mock.json:/config/ai-mock.json
    networks:
      - pms-network

  # ============================================
  # Local LLM Service (Ollama - Optional)
  # ============================================

  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: pms-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - pms-network

  # ============================================
  # Development Tools
  # ============================================

  # PgAdmin - PostgreSQL GUI
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pms-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@pms.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    networks:
      - pms-network
    depends_on:
      - postgres

  # Redis Commander - Redis GUI
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: pms-redis-commander
    environment:
      REDIS_HOSTS: local:redis:6379
    ports:
      - "8082:8081"
    networks:
      - pms-network
    depends_on:
      - redis

  # ============================================
  # Monitoring (Optional - Production에서 필수)
  # ============================================

  # Prometheus - 메트릭 수집
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: pms-prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
  #     - prometheus_data:/prometheus
  #   networks:
  #     - pms-network
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'

  # Grafana - 메트릭 시각화
  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: pms-grafana
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     GF_SECURITY_ADMIN_PASSWORD: admin
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #   networks:
  #     - pms-network
  #   depends_on:
  #     - prometheus

# ============================================
# Networks
# ============================================

networks:
  pms-network:
    driver: bridge

# ============================================
# Volumes
# ============================================

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  pgadmin_data:
    driver: local
  backend_cache:
    driver: local
  ollama_data:
    driver: local
  qdrant_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  neo4j_import:
    driver: local
  neo4j_plugins:
    driver: local
  helix_data:
    driver: local
  chromadb_data:
    driver: local
  # prometheus_data:
  #   driver: local
  # grafana_data:
  #   driver: local
